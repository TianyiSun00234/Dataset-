# Datasets & Websides

## performance evaluation
* [ANALYSING MATHEMATICAL REASONING ABILITIES
OF NEURAL MODELS](https://arxiv.org/pdf/1904.01557v1.pdf)
* [Allen AI](https://allenai.org/data?tag=AllenNLP)


## resources:
* [Allen AI](https://guide.allennlp.org/)
* [paperswithcode](https://paperswithcode.com/task/commonsense-rl)
* [NLU](https://en.wikipedia.org/wiki/Natural-language_understanding)
* [NLG(vs.NLU)](https://en.wikipedia.org/wiki/Natural-language_generation)
* [list of unsolved problems in cs](https://en.wikipedia.org/wiki/List_of_unsolved_problems_in_computer_science#Natural_language_processing_algorithms)
* [Meta-learning for Few-shot Natural Language Processing](https://arxiv.org/abs/2007.09604)([Generalizing from a Few Examples: A Survey on Few-Shot
Learning](https://arxiv.org/pdf/1904.05046.pdf))--> data scarcity and low-resources languages.
* [Ambiguity & Synonymy](https://medium.com/sciforce/biggest-open-problems-in-natural-language-processing-7eb101ccfc9)
* [Open Q in nlp](https://ruder.io/4-biggest-open-problems-in-nlp/)


Bias:
* [Debiased Contrastive Learning](https://arxiv.org/pdf/2007.00224.pdf)
* [Unlearn Dataset Bias in Natural Language Inference by Fitting the Residual](https://arxiv.org/abs/1908.10763)

[Fairness, Ethics, Accountability, and Transparency in NLP](http://web.cs.ucla.edu/~kwchang/publications_area/#FEAT)
[Learning and Inference in Natural Language Processing](http://web.cs.ucla.edu/~kwchang/publications_area/#ml4nlp)


Making text generation factually correct: 
* [FEQA: A Question Answering Evaluation Framework for Faithfulness Assessment in Abstractive Summarization](https://arxiv.org/abs/2005.03754)

Generate novel, creative text in a controllable way: 
* novel: [Delete, Retrieve, Generate: A Simple Approach to Sentiment and Style Transfer](https://arxiv.org/abs/1804.06437)
* creative text: [Pun Generation with Surprise](https://arxiv.org/abs/1904.06828)

cross domain sa & data scarcity:
* [Domain adaptation and sample bias correction](https://cs.nyu.edu/~mohri/domain.html)
* [Transductive Inference](https://cs.nyu.edu/~mohri/transduction.html)
* [cross-domain ensemble](https://www.researchgate.net/publication/330030207_A_General_Cross-Domain_Recommendation_Framework_via_Bayesian_Neural_Network)
* [MTNet: A Neural Approach for Cross-Domain
Recommendation with Unstructured Text](https://www.kdd.org/kdd2018/files/deep-learning-day/DLDay18_paper_5.pdf)

information extraction: 
* [Information Extraction:
Capabilities and Challenges](https://cs.nyu.edu/grishman/tarragona.pdf)


reasoning [video](https://www.youtube.com/watch?v=fKk9KhGRBdI&feature=emb_logo)
* mentioned people :
  * [Tom Mitchell](http://www.cs.cmu.edu/~tom/)
  * [Jaime Carbonell](https://www.cs.cmu.edu/~jgc/)

ambiguity: NP-Hard Problem of NLP
 * [Why](https://www.ijrter.com/papers/volume-4/issue-2/why-is-nlp-an-np-hard-problem-a-short-explanation.pdf)
 * [Approximation of NP-hard problems](https://www.cs.princeton.edu/~arora/publist.html#Course%20Notes%20etc.)

Allen AI
* [Oren Etzioni's talks](https://allenai.org/team/orene)
* [AI Can Help Scientists Find a Covid-19 Vaccine](https://www.wired.com/story/opinion-ai-can-help-find-scientists-find-a-covid-19-vaccine/)
* [GPT-3](https://hai.stanford.edu/blog/gpt-3-intelligent-directors-conversation-oren-etzioni)
